# 百果园舆情监测系统 - 快速开始指南

**版本：** v1.0 MVP
**更新时间：** 2025-11-06
**适用人员：** 百果园客服/公关团队

---

## 🎯 系统简介

这是一个为百果园定制的舆情监测系统，能够自动爬取小红书、抖音、微博、B站上关于"百果园"的用户评论，自动分析情感和分类，并提供人工审核界面。

**核心功能：**
- ✅ 每天自动爬取3次（早上8点、中午13点、晚上8点）
- ✅ 自动情感分析（正面/中性/负面）
- ✅ 自动分类（价格/商品/服务/会员/安全/其他问题）
- ✅ 中文审核界面，一键复制内容
- ✅ 状态管理（未处理/已处理）

---

## 📦 一、部署前准备

### 1.1 服务器要求
- 操作系统：Ubuntu 22.04（推荐）或 CentOS 7+
- 配置：2核4G内存，100GB硬盘
- 网络：能访问外网（需要调用AI API）

### 1.2 环境依赖
系统会自动安装以下软件：
- Python 3.11
- PostgreSQL 15（数据库）
- Playwright（浏览器自动化）

---

## 🚀 二、一键部署（服务器端）

### 2.1 第1步：连接服务器

**Windows用户：**
```bash
# 打开命令提示符（Win+R，输入cmd）
ssh root@你的服务器IP
# 输入密码
```

**Mac用户：**
```bash
# 打开终端
ssh root@你的服务器IP
# 输入密码
```

### 2.2 第2步：下载代码

```bash
# 1. 安装git（如果没有）
apt update && apt install -y git

# 2. 下载代码（替换成实际地址）
cd /root
git clone <代码仓库地址> baiguoyuan
cd baiguoyuan

# 或者手动上传代码包
# 上传 BettaFish-test.zip 到服务器，然后解压
unzip BettaFish-test.zip
cd BettaFish-test
```

### 2.3 第3步：一键安装

```bash
# 给安装脚本执行权限
chmod +x deploy.sh

# 运行安装脚本（会自动安装所有依赖）
./deploy.sh
```

安装脚本会自动完成：
1. 安装Python 3.11
2. 安装PostgreSQL数据库
3. 安装Python依赖包
4. 安装Playwright浏览器
5. 初始化数据库
6. 配置.env文件

**预计时间：10-15分钟**

---

## 🔐 三、平台账号登录（扫码）

### 3.1 为什么需要登录？
爬取社交媒体需要登录账号，每个平台只需登录一次，系统会保存登录状态。

### 3.2 登录步骤

依次登录4个平台：

#### 1️⃣ 小红书
```bash
cd /root/baiguoyuan/MindSpider
python main.py --deep-sentiment --platforms xhs --test
```
- 会显示二维码或弹出浏览器
- 用手机小红书APP扫码登录
- 看到"登录成功"即可

#### 2️⃣ 抖音
```bash
python main.py --deep-sentiment --platforms dy --test
```
- 用手机抖音APP扫码登录

#### 3️⃣ 微博
```bash
python main.py --deep-sentiment --platforms wb --test
```
- 用手机微博APP扫码登录

#### 4️⃣ B站
```bash
python main.py --deep-sentiment --platforms bili --test
```
- 用手机B站APP扫码登录

**总耗时：约10分钟（4个平台 × 2-3分钟）**

---

## 🖥️ 四、启动系统

### 4.1 启动审核界面

```bash
cd /root/baiguoyuan
streamlit run baiguoyuan_review_app.py --server.port 5000
```

访问地址：`http://你的服务器IP:5000`

**看到审核界面，说明成功了！** ✅

### 4.2 启动定时任务守护进程

打开新的终端窗口（或用screen/tmux）：

```bash
cd /root/baiguoyuan
python scheduler_daemon.py
```

会看到：
```
🚀 百果园舆情监测定时任务守护进程启动
当前时间: 2025-11-06 15:30:00
定时任务配置:
  - 早上: 08:00
  - 中午: 13:00
  - 晚上: 20:00
⏰ 定时任务已设置，等待执行...
```

**系统会自动在设定时间执行爬取！** ✅

---

## 📱 五、使用审核界面

### 5.1 打开界面
在浏览器输入：`http://你的服务器IP:5000`

### 5.2 筛选功能

**左侧边栏有4个筛选条件：**
1. **平台**：全部 / 小红书 / 抖音 / 微博 / B站
2. **分类**：全部 / 价格问题 / 商品问题 / 服务问题等
3. **日期**：今天 / 昨天 / 近7天 / 近30天 / 全部
4. **状态**：未处理 / 已处理 / 全部 ⭐

**点击"🔄 刷新数据"更新列表**

### 5.3 查看信息

每条信息显示：
- 📱 **平台**：小红书/抖音/微博/B站
- ⏰ **时间**：发布时间
- 🔥 **热度**：浏览量/点赞数
- 🏷️ **状态**：未处理/已处理
- 🔑 **关键词**：命中的关键词
- 📝 **标题和内容**
- 😊 **情感**：正面/中性/负面（带分数）
- 🏷️ **分类**：价格问题/商品问题等
- 🔗 **链接**：原文链接

### 5.4 操作按钮

每条信息有2个按钮：

#### 📋 **复制内容**
- 点击后会显示完整内容（标题+正文+链接）
- 手动复制后粘贴到百果园工单系统

#### ✅ **标记已处理**
- 点击后状态变为"已处理"
- 下次筛选"未处理"时不会再显示
- 避免重复查看

---

## 🔧 六、常用操作

### 6.1 手动触发一次爬取

如果想立即爬取，不想等定时任务：

```bash
cd /root/baiguoyuan/MindSpider
python main.py --deep-sentiment --platforms xhs dy wb bili --max-keywords 10 --max-notes 20
```

### 6.2 查看爬取日志

```bash
# 查看定时任务日志
tail -f /root/baiguoyuan/logs/scheduler.log

# 查看爬虫日志
tail -f /root/baiguoyuan/MindSpider/logs/crawler.log
```

### 6.3 停止系统

**停止审核界面：**
```bash
# 找到进程ID
ps aux | grep streamlit
# 停止进程
kill -9 <进程ID>
```

**停止定时任务：**
```bash
# 在运行scheduler_daemon.py的终端按 Ctrl+C
```

### 6.4 重启系统

```bash
# 重启审核界面
cd /root/baiguoyuan
streamlit run baiguoyuan_review_app.py --server.port 5000 &

# 重启定时任务
python scheduler_daemon.py &
```

---

## 📊 七、数据查看

### 7.1 数据库位置
- SQLite数据库：`/root/baiguoyuan/baiguoyuan_sentiment.db`
- 包含所有爬取的舆情信息

### 7.2 导出数据

如果想导出Excel：

```bash
cd /root/baiguoyuan
python export_data.py --date 2025-11-06 --format excel
```

会生成：`exports/baiguoyuan_sentiment_2025-11-06.xlsx`

---

## ❓ 八、常见问题

### Q1：审核界面打不开？

**检查：**
```bash
# 1. 检查Streamlit是否运行
ps aux | grep streamlit

# 2. 检查端口是否开放
netstat -tulpn | grep 5000

# 3. 检查防火墙
ufw status
ufw allow 5000
```

### Q2：定时任务没有执行？

**检查：**
```bash
# 1. 查看定时任务进程
ps aux | grep scheduler_daemon

# 2. 查看日志
tail -50 logs/scheduler.log
```

### Q3：爬取失败怎么办？

**可能原因：**
1. **登录过期**：重新扫码登录（3-6个月过期一次）
2. **网络问题**：检查服务器能否访问外网
3. **平台反爬**：等待一段时间再试

**解决方法：**
```bash
# 单独测试某个平台
cd /root/baiguoyuan/MindSpider
python main.py --deep-sentiment --platforms xhs --test

# 看报错信息，如果提示登录失效，重新扫码
```

### Q4：数据库满了怎么办？

**清理历史数据：**
```bash
cd /root/baiguoyuan
python cleanup_old_data.py --days 90  # 删除90天前的数据
```

### Q5：如何修改爬取频率？

**编辑定时任务文件：**
```bash
nano /root/baiguoyuan/scheduler_daemon.py

# 修改这3行：
schedule.every().day.at("08:00").do(morning_task)  # 早上时间
schedule.every().day.at("13:00").do(noon_task)     # 中午时间
schedule.every().day.at("20:00").do(evening_task)  # 晚上时间

# 保存后重启定时任务
```

---

## 📞 九、技术支持

### 遇到问题怎么办？

1. **查看日志**：
   ```bash
   tail -100 logs/scheduler.log  # 定时任务日志
   tail -100 MindSpider/logs/crawler.log  # 爬虫日志
   ```

2. **截图报错信息**

3. **联系技术人员**（提供日志和截图）

---

## 🎉 十、完成！

✅ **系统已部署成功！**

现在你可以：
1. 打开 `http://服务器IP:5000` 查看审核界面
2. 等待定时任务自动执行（早上8点、中午13点、晚上8点）
3. 或手动触发一次爬取测试

**祝使用愉快！** 🚀

---

**文档版本：** v1.0
**最后更新：** 2025-11-06
