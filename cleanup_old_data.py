#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç™¾æœå›­èˆ†æƒ…ç³»ç»Ÿ - å†å²æ•°æ®æ¸…ç†è„šæœ¬
åŠŸèƒ½: è‡ªåŠ¨åˆ é™¤14å¤©å‰çš„èˆ†æƒ…æ•°æ®,å¹¶å¤‡ä»½
"""

import sqlite3
import shutil
from datetime import datetime, timedelta
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é…ç½®
DB_PATH = "baiguoyuan_sentiment.db"
RETENTION_DAYS = 14  # ä¿ç•™14å¤©
BACKUP_DIR = Path("backups")


def create_backup():
    """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
    try:
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        BACKUP_DIR.mkdir(exist_ok=True)

        # å¤‡ä»½æ–‡ä»¶å: baiguoyuan_sentiment_backup_20250108_120000.db
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = BACKUP_DIR / f"baiguoyuan_sentiment_backup_{timestamp}.db"

        # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
        shutil.copy2(DB_PATH, backup_path)

        logger.info(f"âœ… æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_path}")
        return True
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
        return False


def cleanup_old_backups(keep_days=30):
    """æ¸…ç†è¶…è¿‡30å¤©çš„å¤‡ä»½æ–‡ä»¶"""
    try:
        if not BACKUP_DIR.exists():
            return

        cutoff_date = datetime.now() - timedelta(days=keep_days)
        deleted_count = 0

        for backup_file in BACKUP_DIR.glob("baiguoyuan_sentiment_backup_*.db"):
            # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            mtime = datetime.fromtimestamp(backup_file.stat().st_mtime)

            if mtime < cutoff_date:
                backup_file.unlink()
                deleted_count += 1
                logger.info(f"ğŸ—‘ï¸  åˆ é™¤æ—§å¤‡ä»½: {backup_file.name}")

        if deleted_count > 0:
            logger.info(f"âœ… æ¸…ç†äº† {deleted_count} ä¸ªè¶…è¿‡{keep_days}å¤©çš„å¤‡ä»½æ–‡ä»¶")
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")


def cleanup_old_data():
    """åˆ é™¤14å¤©å‰çš„èˆ†æƒ…æ•°æ®"""
    try:
        # è®¡ç®—æˆªæ­¢æ—¥æœŸ
        cutoff_date = datetime.now() - timedelta(days=RETENTION_DAYS)
        cutoff_str = cutoff_date.strftime('%Y-%m-%d %H:%M:%S')

        logger.info("=" * 60)
        logger.info("å¼€å§‹æ¸…ç†å†å²èˆ†æƒ…æ•°æ®")
        logger.info(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ä¿ç•™å¤©æ•°: {RETENTION_DAYS}å¤©")
        logger.info(f"æˆªæ­¢æ—¥æœŸ: {cutoff_str}")
        logger.info("=" * 60)

        # è¿æ¥æ•°æ®åº“
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        # æŸ¥è¯¢è¦åˆ é™¤çš„æ•°æ®æ•°é‡
        cursor.execute("""
            SELECT COUNT(*) FROM sentiment_data
            WHERE created_at < ?
        """, (cutoff_str,))

        to_delete_count = cursor.fetchone()[0]

        if to_delete_count == 0:
            logger.info("â„¹ï¸  æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ•°æ®")
            conn.close()
            return 0

        logger.info(f"ğŸ“Š å¾…åˆ é™¤æ•°æ®: {to_delete_count} æ¡")

        # å…ˆå¤‡ä»½å†åˆ é™¤
        logger.info("ğŸ“¦ æ­£åœ¨å¤‡ä»½æ•°æ®åº“...")
        if not create_backup():
            logger.warning("âš ï¸  å¤‡ä»½å¤±è´¥,ä½†ç»§ç»­æ‰§è¡Œæ¸…ç†...")

        # æ‰§è¡Œåˆ é™¤
        logger.info("ğŸ—‘ï¸  æ­£åœ¨åˆ é™¤æ—§æ•°æ®...")
        cursor.execute("""
            DELETE FROM sentiment_data
            WHERE created_at < ?
        """, (cutoff_str,))

        deleted = cursor.rowcount
        conn.commit()

        # ä¼˜åŒ–æ•°æ®åº“(å›æ”¶ç©ºé—´)
        logger.info("ğŸ”§ æ­£åœ¨ä¼˜åŒ–æ•°æ®åº“...")
        cursor.execute("VACUUM")
        conn.commit()

        conn.close()

        logger.info("=" * 60)
        logger.info(f"âœ… æ¸…ç†å®Œæˆ!")
        logger.info(f"åˆ é™¤æ•°æ®: {deleted} æ¡")
        logger.info(f"æ•°æ®åº“å·²ä¼˜åŒ–")
        logger.info("=" * 60)

        # æ¸…ç†æ—§å¤‡ä»½
        cleanup_old_backups(keep_days=30)

        return deleted

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
        return -1


def get_database_stats():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        # æ€»æ•°æ®é‡
        cursor.execute("SELECT COUNT(*) FROM sentiment_data")
        total_count = cursor.fetchone()[0]

        # æœ€æ—©æ•°æ®æ—¶é—´
        cursor.execute("SELECT MIN(created_at) FROM sentiment_data")
        earliest = cursor.fetchone()[0]

        # æœ€æ–°æ•°æ®æ—¶é—´
        cursor.execute("SELECT MAX(created_at) FROM sentiment_data")
        latest = cursor.fetchone()[0]

        # æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_size = Path(DB_PATH).stat().st_size / 1024 / 1024  # MB

        conn.close()

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
        logger.info("=" * 60)
        logger.info(f"æ€»æ•°æ®é‡: {total_count:,} æ¡")
        logger.info(f"æœ€æ—©æ•°æ®: {earliest or 'æ— '}")
        logger.info(f"æœ€æ–°æ•°æ®: {latest or 'æ— '}")
        logger.info(f"æ•°æ®åº“å¤§å°: {db_size:.2f} MB")
        logger.info("=" * 60 + "\n")

    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("\nğŸš€ ç™¾æœå›­èˆ†æƒ…æ•°æ®æ¸…ç†è„šæœ¬å¯åŠ¨\n")

    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    if not Path(DB_PATH).exists():
        logger.error(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DB_PATH}")
        return

    # æ˜¾ç¤ºæ¸…ç†å‰ç»Ÿè®¡
    logger.info("ğŸ“Š æ¸…ç†å‰æ•°æ®ç»Ÿè®¡:")
    get_database_stats()

    # æ‰§è¡Œæ¸…ç†
    deleted = cleanup_old_data()

    if deleted >= 0:
        # æ˜¾ç¤ºæ¸…ç†åç»Ÿè®¡
        logger.info("\nğŸ“Š æ¸…ç†åæ•°æ®ç»Ÿè®¡:")
        get_database_stats()
        logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!\n")
    else:
        logger.error("âŒ æ¸…ç†ä»»åŠ¡å¤±è´¥!\n")


if __name__ == "__main__":
    main()
